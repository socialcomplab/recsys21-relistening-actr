{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q data/actr_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\"user1\", \"song1\", datetime.datetime(2000, 1, 1, 0)],\n",
    "    [\"user1\", \"song1\", datetime.datetime(2000, 1, 1, 0)],\n",
    "    [\"user1\", \"song2\", datetime.datetime(2000, 1, 1, 1)],\n",
    "    [\"user1\", \"song2\", datetime.datetime(2000, 1, 1, 1)],\n",
    "    [\"user1\", \"song2\", datetime.datetime(2000, 1, 1, 1)],\n",
    "    [\"user1\", \"song2\", datetime.datetime(2000, 1, 1, 1)],\n",
    "    [\"user1\", \"song1\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user1\", \"song2\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user1\", \"song1\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    \n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "    [\"user2\", \"song3\", datetime.datetime(2000, 1, 1, 2)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame(data, columns=[\"user\", \"item\", \"timestamp\"]).set_index(\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"v\"] = np.random.rand(len(events))\n",
    "events[\"a\"] = np.random.rand(len(events))\n",
    "events[\"d\"] = np.random.rand(len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"reward\"] = np.random.choice([-1] + 9*[1], len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"session\"] = np.random.choice([1] + 2*[0], len(events)).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>v</th>\n",
       "      <th>a</th>\n",
       "      <th>d</th>\n",
       "      <th>reward</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>song1</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>0.082969</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0.864947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>song1</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>0.838377</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>song2</td>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "      <td>0.098741</td>\n",
       "      <td>0.133426</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>song2</td>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "      <td>0.492087</td>\n",
       "      <td>0.361749</td>\n",
       "      <td>0.614685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>song2</td>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "      <td>0.928530</td>\n",
       "      <td>0.509011</td>\n",
       "      <td>0.841318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item           timestamp         v         a         d  reward  \\\n",
       "user                                                                     \n",
       "user1  song1 2000-01-01 00:00:00  0.082969  0.094969  0.864947       1   \n",
       "user1  song1 2000-01-01 00:00:00  0.838377  0.792869  0.027937       1   \n",
       "user1  song2 2000-01-01 01:00:00  0.098741  0.133426  0.643574       1   \n",
       "user1  song2 2000-01-01 01:00:00  0.492087  0.361749  0.614685       1   \n",
       "user1  song2 2000-01-01 01:00:00  0.928530  0.509011  0.841318       1   \n",
       "\n",
       "       session  \n",
       "user            \n",
       "user1        0  \n",
       "user1        0  \n",
       "user1        1  \n",
       "user1        1  \n",
       "user1        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_user = \"user1\"\n",
    "user_events = events.loc[example_user]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing baseline_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile baseline_models.py\n",
    "import numpy as np\n",
    "\n",
    "class MostRecent:\n",
    "    def __str__(self):\n",
    "        return type(self).__name__\n",
    "    \n",
    "    def recommend_next(self, user_events):\n",
    "        return user_events[\"item\"].values[-1]\n",
    "    \n",
    "    def recommend(self, user_events, topn):\n",
    "        return user_events[\"item\"].iloc[::-1].unique().tolist()[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run baseline_models.py\n",
    "\n",
    "mr = MostRecent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next item prediction\n",
    "assert mr.recommend_next(user_events) == user_events[\"item\"].values[-1]\n",
    "mr.recommend_next(user_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TopN item predictions\n",
    "assert mr.recommend(user_events, 3)[0] == mr.recommend_next(user_events)\n",
    "mr.recommend(user_events, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transition_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transition_models.py\n",
    "class UserBasedTransitionProbability:\n",
    "    def __str__(self):\n",
    "        return type(self).__name__\n",
    "        \n",
    "    def recommend_next(self, user_events):\n",
    "        cur_item = user_events[\"item\"].iloc[-1]\n",
    "        events_on_cur_item = user_events[(user_events[\"item\"] == cur_item).shift().fillna(False)]\n",
    "        if not events_on_cur_item.empty:\n",
    "            return events_on_cur_item[\"item\"].mode().values[-1]\n",
    "        else:\n",
    "            # Return no recommendation\n",
    "            return -1\n",
    "        \n",
    "    def recommend(self, user_events, topn):\n",
    "        cur_item = user_events[\"item\"].iloc[-1]\n",
    "        events_on_cur_item = user_events[(user_events[\"item\"] == cur_item).shift().fillna(False)]\n",
    "        return events_on_cur_item[\"item\"].value_counts().index.tolist()[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run transition_models.py\n",
    "\n",
    "ubtp = UserBasedTransitionProbability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ubtp.recommend_next(user_events)\n",
    "ubtp.recommend_next(user_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['song2', 'song1'], ['song2', 'song1'], ['song2'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert ubtp.recommend(user_events, 3)[0] == ubtp.recommend_next(user_events)\n",
    "ubtp.recommend(user_events, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting emomem_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile emomem_model.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, special\n",
    "import operator\n",
    "\n",
    "class DecayFitterMixin:\n",
    "    def fit(self, events):\n",
    "        delta = events.groupby([\"user\", \"item\"])[\"timestamp\"].diff().dropna().dt.total_seconds() / 3600\n",
    "        delta = delta[delta != 0]\n",
    "        delta_bins = delta.value_counts()\n",
    "        log_x = np.log10(delta_bins.index.tolist())\n",
    "        log_y = np.log10(delta_bins.values.tolist())\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(log_x, log_y)\n",
    "        self.decay = -slope\n",
    "        return slope\n",
    "    \n",
    "class ScoreToRecommenderMixin:\n",
    "    \"\"\"Requires a score(self, user_events) function.\"\"\"\n",
    "    def recommend_next(self, user_events):\n",
    "        item_scores = self.score(user_events)\n",
    "        return item_scores.idxmax()\n",
    "    \n",
    "    def recommend(self, user_events, topn):\n",
    "        item_scores = self.score(user_events)\n",
    "        return item_scores.nlargest(topn).index.tolist()\n",
    "    \n",
    "class BaseLevelComponent(ScoreToRecommenderMixin, DecayFitterMixin):\n",
    "    \"\"\"Models occurence.\"\"\"\n",
    "    def __init__(self, decay=0.5, time_col=\"timestamp\"):\n",
    "        self.decay = decay\n",
    "        self.time_col = time_col\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.decay == 0.5:\n",
    "            return type(self).__name__\n",
    "        else:\n",
    "            return type(self).__name__ + str(self.decay)\n",
    "        \n",
    "    def score(self, user_events):\n",
    "        user_events = user_events.copy()\n",
    "        ts_ref = user_events[\"timestamp\"].iloc[-1]\n",
    "        \n",
    "        user_events[\"ts_diff\"] = (-(user_events[self.time_col] - ts_ref) + pd.Timedelta(\"1hour\")).dt.total_seconds()/3600\n",
    "        bll_scores = user_events.groupby(\"item\", sort=False)[\"ts_diff\"].apply(lambda x: np.sum(np.power(x.values, -self.decay)))\n",
    "        return bll_scores\n",
    "        \n",
    "class AssociativeComponent(ScoreToRecommenderMixin):\n",
    "    \"\"\"Models co-occurence.\"\"\"\n",
    "    def __init__(self, session_col=\"session\"):\n",
    "        self.session_col = session_col\n",
    "        \n",
    "    def __str__(self):\n",
    "        return type(self).__name__\n",
    "        \n",
    "    def score(self, user_events):\n",
    "        context_item = user_events[\"item\"].iloc[-1]\n",
    "        context_sessions = set(user_events[user_events[\"item\"] == context_item][self.session_col].unique())\n",
    "        \n",
    "        num_sessions = user_events[self.session_col].nunique()\n",
    "        probability_of_item = user_events.groupby(\"item\")[self.session_col].nunique() / num_sessions\n",
    "        \n",
    "        def overlap(sessions):\n",
    "            return len(set(sessions.unique()).intersection(context_sessions))\n",
    "        \n",
    "        overlap_sessions = user_events.groupby(\"item\")[self.session_col].apply(overlap)\n",
    "        condidtional_probability = overlap_sessions/len(context_sessions)\n",
    "        \n",
    "        return condidtional_probability/probability_of_item\n",
    "        \n",
    "class PartialMatchingComponent(ScoreToRecommenderMixin):\n",
    "    \"\"\"Models similarity.\"\"\"\n",
    "    def __init__(self, name=None, feature_cols=None, similarity_function=np.dot):\n",
    "        self.name = name if name else type(self).__name__\n",
    "        self.feature_cols = feature_cols\n",
    "        self.similarity_function = similarity_function\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "        \n",
    "    def score(self, user_events):\n",
    "        context_features = user_events[self.feature_cols].iloc[-1]\n",
    "        \n",
    "        items = user_events.drop_duplicates(subset=[\"item\"])\n",
    "        item_index = items[\"item\"].values\n",
    "        cand_features = items[self.feature_cols].values\n",
    "        \n",
    "        pm_scores = self.similarity_function(cand_features, context_features)\n",
    "        return pd.Series(data=pm_scores, index=item_index)\n",
    "        \n",
    "class ValuationComponent(ScoreToRecommenderMixin):\n",
    "    \"\"\"Models affect.\"\"\"\n",
    "    def __init__(self, name=None, learning_rate=0.2, initial_valuation=0, reward_col=\"reward\"):\n",
    "        self.name = name if name else type(self).__name__\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initial_valuation = initial_valuation\n",
    "        self.reward_col = reward_col\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "        \n",
    "    def score(self, user_events):\n",
    "        def update_valuation(prev, reward=1, lr=0.05):\n",
    "            return prev + lr * (reward - prev)\n",
    "        \n",
    "        def aggreagte_valuation(reward_s):\n",
    "            valuation = self.initial_valuation\n",
    "            for reward in reward_s.values:\n",
    "                valuation = update_valuation(valuation, reward, self.learning_rate)\n",
    "            return valuation\n",
    "        \n",
    "        valuation_scores = user_events.groupby(\"item\")[self.reward_col].apply(aggreagte_valuation)\n",
    "        return valuation_scores\n",
    "    \n",
    "class NoiseComponent(ScoreToRecommenderMixin):\n",
    "    \"\"\"Adds randomnes.\"\"\"\n",
    "    def __init__(self, seed=42):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return type(self).__name__\n",
    "    \n",
    "    def score(self, user_events):\n",
    "        return pd.Series(data=self.rng.random(user_events[\"item\"].nunique()), index=user_events[\"item\"].unique())\n",
    "    \n",
    "class ActrRecommender(ScoreToRecommenderMixin):\n",
    "    \"\"\"Combines multiple components.\"\"\"\n",
    "    def __init__(self, components, weights=None, softmax=True, name=None, use_normalize_trick=False):\n",
    "        self.components = components\n",
    "        self.weights = weights if weights else [1]*len(components)\n",
    "        self.softmax = softmax\n",
    "        self.name = name if name else type(self).__name__ + \"(\" + \",\".join(map(str, self.components)) + \")\"\n",
    "        self.use_normalize_trick = use_normalize_trick\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "        \n",
    "    def score(self, user_events):\n",
    "        scores = pd.Series()\n",
    "        \n",
    "        for comp, w_c in zip(self.components, self.weights):\n",
    "            comp_scores = comp.score(user_events)\n",
    "            if self.softmax:\n",
    "                if self.use_normalize_trick:\n",
    "                    # https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "                    comp_scores = comp_scores - np.max(comp_scores)\n",
    "                comp_scores = special.softmax(comp_scores)\n",
    "            comp_scores = comp_scores * w_c\n",
    "            scores = scores.combine(comp_scores, operator.add, 0)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['song1', 'song2'],\n",
       " ['song1', 'song2'],\n",
       " ['song1', 'song2'],\n",
       " ['song2', 'song1'],\n",
       " ['song1', 'song2'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run emomem_model.py\n",
    "\n",
    "bll_new = BaseLevelComponent(decay=2)\n",
    "assert bll_new.recommend_next(user_events) == bll_new.recommend(user_events, 3)[0]\n",
    "\n",
    "assoc = AssociativeComponent()\n",
    "assert assoc.recommend_next(user_events) == assoc.recommend(user_events, 3)[0]\n",
    "\n",
    "emo_new = PartialMatchingComponent(feature_cols=[\"v\", \"a\", \"d\"])\n",
    "assert emo_new.recommend_next(user_events) == emo_new.recommend(user_events, 3)[0]\n",
    "\n",
    "valu = ValuationComponent()\n",
    "assert valu.recommend_next(user_events) == valu.recommend(user_events, 3)[0]\n",
    "\n",
    "noise = NoiseComponent()\n",
    "\n",
    "assoc.recommend(user_events, 3), bll_new.recommend(user_events, 3), emo_new.recommend(user_events, 3), valu.recommend(user_events, 3), noise.recommend(user_events, 3), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActrRecommender(BaseLevelComponent,AssociativeComponent,PartialMatchingComponent,ValuationComponent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['song1', 'song2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actr = ActrRecommender([bll_new, assoc, emo_new, valu], weights=[2, 1, 1, 1], softmax=True)\n",
    "print(actr)\n",
    "assert actr.recommend_next(user_events) == actr.recommend(user_events, 3)[0]\n",
    "\n",
    "actr.recommend(user_events, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9940794707796661\n"
     ]
    }
   ],
   "source": [
    "def valuation(prev, reward=1, lr=0.05):\n",
    "    return prev + lr * (reward - prev)\n",
    "\n",
    "val = 0\n",
    "normal_reward = 1\n",
    "alt_reward = -1\n",
    "alt_sim = False\n",
    "# alt_sim = 8*[0]+2*[1]\n",
    "for i in range(100):\n",
    "    if alt_sim and np.random.choice(alt_sim):  # simulate negative rewards\n",
    "        val = valuation(val, alt_reward)\n",
    "        print(\"alt: \" + str(val))\n",
    "        continue\n",
    "    val = valuation(val, normal_reward)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.7693859886415\n",
      "4.123407869374147\n"
     ]
    }
   ],
   "source": [
    "ts = range(1, 1000)\n",
    "\n",
    "tas = 0\n",
    "for t in ts:\n",
    "    a = np.power(t, -0.5)\n",
    "    tas += a\n",
    "print(tas)\n",
    "print(np.log(tas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010780389779679721, 61.7693859886415)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(3, -np.log(tas)), tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuation(prev, reward):\n",
    "    return prev + 0.05 * (reward - prev)\n",
    "\n",
    "rew_list = np.random.choice([-1]+[1]*9, 100)\n",
    "valuation_ufunc = np.frompyfunc(valuation, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205833149740941"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuation_ufunc.reduce(rew_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polarice",
   "language": "python",
   "name": "polarice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
